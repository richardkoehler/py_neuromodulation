{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [dyskinesia project] Preprocessing Neurophysiology Data\n",
    "\n",
    "\n",
    "This notebooks helps to Step-by-Step select and preprocess ECoG and LFP (STN electrodes) data within the ReTune-Dyskinesia project.\n",
    "<b> Data is required to converted into the BIDS-standard. </b>\n",
    "\n",
    "For automated preprocessing, check: XXXX.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Loading packages and functions, defining paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python and external packages\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import json\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from dataclasses import dataclass, field, fields\n",
    "from collections import namedtuple\n",
    "from typing import Any\n",
    "from itertools import compress\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "#mne\n",
    "import mne_bids\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python sys 3.9.7 (default, Sep 16 2021, 08:50:36) \n",
      "[Clang 10.0.0 ]\n",
      "pandas 1.3.4\n",
      "numpy 1.20.3\n",
      "mne_bids 0.9\n",
      "mne 0.24.1\n",
      "sci-py 1.7.1\n",
      "sci-kit learn 1.0.1\n"
     ]
    }
   ],
   "source": [
    "# check some package versions for documentation and reproducability\n",
    "print('Python sys', sys.version)\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "print('mne_bids', mne_bids.__version__)\n",
    "print('mne', mne.__version__)\n",
    "print('sci-py', scipy.__version__)\n",
    "print('sci-kit learn', sk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define local storage directories\n",
    "projectpath = '/Users/jeroenhabets/Research/CHARITE/projects/dyskinesia_neurophys'\n",
    "datapath = os.path.join(projectpath, 'data/BIDS_Berlin_ECOG_LFP/rawdata')\n",
    "codepath = os.path.join(projectpath, 'code')\n",
    "figpath = os.path.join(projectpath, 'figures')\n",
    "pynmd_path = os.path.join(codepath, 'py_neuromodulation')\n",
    "\n",
    "# define external storage directories\n",
    "ext_projectpath = '/Volumes/JH/Research/CHARITE/projects/dyskinesia_neurophys'\n",
    "ext_datapath = os.path.join(ext_projectpath, 'data/BIDS_Berlin_ECOG_LFP/rawdata')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jeroenhabets/Research/CHARITE/projects/dyskinesia_neurophys/code/py_neuromodulation\n"
     ]
    }
   ],
   "source": [
    "# import from py_neuromodulation after setting directory\n",
    "os.chdir(pynmd_path)\n",
    "print(os.getcwd())\n",
    "\n",
    "import dyskinesia.preprocessing as preproc\n",
    "import dyskinesia.reref as reref\n",
    "import dyskinesia.preproc_artefacts as artefacts\n",
    "import dyskinesia.preproc_filters as fltrs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data selection, defining Settings\n",
    "\n",
    "- First DataClass defines which run/data-file should be used (via RunInfo)\n",
    "- Second DataClass creates MNE-objects ordered by data-type (via RunRawData) \n",
    "\n",
    "\n",
    "Note that the resulting Data-Class Objects do not contain the actual data yet (!)\n",
    "- Create RawBrainVision data-objects: load data with rawRun1.ecog.load_data() (incl. internal mne-functionality)\n",
    "- Create np.array's: load data with rawRun1.ecog.get_data(), use return_times=True to return two tuples (data, times); (used in preprocessing.py functions)\n",
    "\n",
    "BIDS-RAW Data Structure Info:\n",
    "- Grouped MNE BIDS Raw Object consists all channels within the group,\n",
    "e.g. lfp_left, lfp_left, ecog, acc. Each channel (rawRun1.ecog[0])\n",
    "is a tuple with the first object a ndarray of shape 1, N_samples.\n",
    "- Calling rawRun1.ecog[0][0] gives the ndarray containing only data-points.\n",
    "- Calling rawRun1.ecog[1] gives the ndarray containing the time stamps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Settings definition\n",
    "\n",
    "\n",
    "TODO: Create .py + .json scripts for automated pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define structures (namedtuples) to store Default settings\n",
    "PreprocSettings = namedtuple('PreprocSettings', (\n",
    "    'win_len '\n",
    "    'artfct_sd_tresh '\n",
    "    'bandpass_f '\n",
    "    'transBW '\n",
    "    'notchW '\n",
    "    'Fs_orig '\n",
    "    'Fs_resample '\n",
    "    'settings_f_name '\n",
    "    'fig_path '))\n",
    "Settings = namedtuple('Settings', 'lfp_left lfp_right ecog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_lfp_settings = [1, 2.5, (1, 120), 10, 2, 4000, 800, 'v0.1 Jan22', figpath]\n",
    "default_ecog_settings = [1, 2.5, (1, 120), 10, 2, 4000, 800, 'v0.1 Jan22', figpath]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = Settings(\n",
    "    PreprocSettings(*default_lfp_settings),\n",
    "    PreprocSettings(*default_lfp_settings),\n",
    "    PreprocSettings(*default_ecog_settings),\n",
    "# '*' before lists unpacks the list-values as seperate args\n",
    ")\n",
    "groups = list(settings._fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Patient and Recording information\n",
    "\n",
    "\n",
    "TODO: Create .py + .json scripts for automated pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE PTATIENT-RUN SETTINGS\n",
    "sub = '008'\n",
    "ses = 'EphysMedOn02'\n",
    "task = 'Rest'\n",
    "acq = 'StimOffLD00'\n",
    "run = '01'\n",
    "sourcepath = ext_datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------------ BIDS DATA INFO ------------\n",
      "The raw-bids-object contains 47 channels with 2444946 datapoints and sample freq  4000.0 Hz\n",
      "Bad channels are: ['LFP_L_16_STN_BS'] \n",
      "\n",
      "BIDS contains:\n",
      "6 ECOG channels,\n",
      "31 DBS channels: (15 left, 16 right), \n",
      "2 EMG channels, \n",
      "1 ECG channel(s), \n",
      "6 Accelerometry (misc) channels.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeroenhabets/Research/CHARITE/projects/dyskinesia_neurophys/code/py_neuromodulation/dyskinesia/preprocessing.py:89: RuntimeWarning: Did not find any events.tsv associated with sub-008_ses-EphysMedOn02_task-Rest_acq-StimOffLD00_run-01.\n",
      "\n",
      "The search_str was \"/Volumes/JH/Research/CHARITE/projects/dyskinesia_neurophys/data/BIDS_Berlin_ECOG_LFP/rawdata/sub-008/**/ieeg/sub-008_ses-EphysMedOn02*events.tsv\"\n",
      "  self.acc = self.bids.copy().pick_types(misc=True, exclude='bads')\n",
      "/Users/jeroenhabets/Research/CHARITE/projects/dyskinesia_neurophys/code/py_neuromodulation/dyskinesia/preprocessing.py:89: RuntimeWarning: Defaulting coordinate frame to unknown from coordinate system input Other\n",
      "  self.acc = self.bids.copy().pick_types(misc=True, exclude='bads')\n",
      "/Users/jeroenhabets/Research/CHARITE/projects/dyskinesia_neurophys/code/py_neuromodulation/dyskinesia/preprocessing.py:89: RuntimeWarning: Fiducial point nasion not found, assuming identity unknown to head transformation\n",
      "  self.acc = self.bids.copy().pick_types(misc=True, exclude='bads')\n"
     ]
    }
   ],
   "source": [
    "# create specific patient-run BIDS-Object for further pre-processing\n",
    "importlib.reload(preproc)\n",
    "runInfo0 = preproc.RunInfo(\n",
    "    sub=sub,\n",
    "    ses=ses,\n",
    "    task=task,\n",
    "    acq=acq,\n",
    "    run=run,\n",
    "    sourcepath=sourcepath,\n",
    "    preproc_sett=settings.lfp_left.settings_f_name,\n",
    "    fig_path=figpath,\n",
    ")\n",
    "rawRun = preproc.RunRawData(bidspath=runInfo0.bidspath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional viewer for un-processed data with MNE's interactive viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load grouped BIDS-Objects:\n",
    "# rawRun1.ecog.load_data()\n",
    "\n",
    "# to visualize non-pre-processed data PSD's\n",
    "# for interactive plotter: activate matplotlib qt line\n",
    "# %matplotlib qt\n",
    "# %matplotlib inline\n",
    "\n",
    "# rawRun1.lfp_left.plot()\n",
    "# rawRun1.lfp_left.plot_psd(n_fft=1024)\n",
    "# rawRun1.ecog.plot_psd(n_fft=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Automated Artefact Removal (incl. Visualization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bidspath\n",
      "bids\n",
      "lfp\n",
      "lfp_left\n",
      "Reading 0 ... 2444945  =      0.000 ...   611.236 secs...\n",
      "lfp_right\n",
      "Reading 0 ... 2444945  =      0.000 ...   611.236 secs...\n",
      "ecog\n",
      "Reading 0 ... 2444945  =      0.000 ...   611.236 secs...\n",
      "acc\n",
      "emg\n",
      "ecg\n"
     ]
    }
   ],
   "source": [
    "# Actual Loading of the Data from BIDS-files\n",
    "\n",
    "# data_raw is filled with loaded mne-bids data per group\n",
    "data_raw = {}\n",
    "for field in rawRun.__dataclass_fields__:\n",
    "    print(field)\n",
    "    # loops over variables within the data class\n",
    "    if str(field)[:4] == 'lfp_':\n",
    "        data_raw[str(field)] = getattr(rawRun, field).load_data()\n",
    "    elif str(field)[:4] == 'ecog':\n",
    "        data_raw[str(field)] = getattr(rawRun, field).load_data()\n",
    "\n",
    "ch_names = {}\n",
    "for group in groups:\n",
    "    ch_names[group] = data_raw[group].info['ch_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START ARTEFACT REMOVAL: lfp_left\n",
      "Ch 1: 0.0% is NaN (artefact or zero)\n",
      "Ch 2: 0.0% is NaN (artefact or zero)\n",
      "Ch 3: 0.0% is NaN (artefact or zero)\n",
      "Ch 4: 0.0% is NaN (artefact or zero)\n",
      "Ch 5: 0.0% is NaN (artefact or zero)\n",
      "Ch 6: 0.0% is NaN (artefact or zero)\n",
      "Ch 7: 0.16% is NaN (artefact or zero)\n",
      "Ch 8: 0.16% is NaN (artefact or zero)\n",
      "Ch 9: 0.0% is NaN (artefact or zero)\n",
      "Ch 10: 0.0% is NaN (artefact or zero)\n",
      "Ch 11: 0.0% is NaN (artefact or zero)\n",
      "Ch 12: 0.0% is NaN (artefact or zero)\n",
      "Ch 13: 0.0% is NaN (artefact or zero)\n",
      "Ch 14: 0.0% is NaN (artefact or zero)\n",
      "Ch 15: 0.0% is NaN (artefact or zero)\n",
      "START ARTEFACT REMOVAL: lfp_right\n",
      "Ch 1: 0.65% is NaN (artefact or zero)\n",
      "Ch 2: 100.0% is NaN (artefact or zero)\n",
      "Ch 3: 23.08% is NaN (artefact or zero)\n",
      "Ch 4: 0.33% is NaN (artefact or zero)\n",
      "Ch 5: 5.56% is NaN (artefact or zero)\n",
      "Ch 6: 100.0% is NaN (artefact or zero)\n",
      "Ch 7: 100.0% is NaN (artefact or zero)\n",
      "Ch 8: 0.65% is NaN (artefact or zero)\n",
      "Ch 9: 0.0% is NaN (artefact or zero)\n",
      "Ch 10: 0.0% is NaN (artefact or zero)\n",
      "Ch 11: 2.45% is NaN (artefact or zero)\n",
      "Ch 12: 2.62% is NaN (artefact or zero)\n",
      "Ch 13: 4.09% is NaN (artefact or zero)\n",
      "Ch 14: 5.56% is NaN (artefact or zero)\n",
      "Ch 15: 6.22% is NaN (artefact or zero)\n",
      "Ch 16: 0.98% is NaN (artefact or zero)\n",
      "START ARTEFACT REMOVAL: ecog\n",
      "Ch 1: 0.33% is NaN (artefact or zero)\n",
      "Ch 2: 7.04% is NaN (artefact or zero)\n",
      "Ch 3: 0.0% is NaN (artefact or zero)\n",
      "Ch 4: 0.0% is NaN (artefact or zero)\n",
      "Ch 5: 1.96% is NaN (artefact or zero)\n",
      "Ch 6: 0.0% is NaN (artefact or zero)\n"
     ]
    }
   ],
   "source": [
    "# Aretefact Removal\n",
    "\n",
    "importlib.reload(preproc)\n",
    "data_clean = {}\n",
    "ch_nms_clean = {}\n",
    "save_dir = os.path.join(\n",
    "    runInfo0.fig_path,\n",
    "    'preprocessing',\n",
    "    runInfo0.store_str,\n",
    "    runInfo0.preproc_sett,\n",
    "    )\n",
    "# save = None\n",
    "for group in groups:\n",
    "    data_clean[group], ch_nms_clean[group] = artefacts.artefact_selection(\n",
    "        bids_dict=data_raw,  # raw BIDS group to process\n",
    "        group=group,\n",
    "        win_len=getattr(settings, group).win_len,\n",
    "        n_stds_cut=getattr(settings, group).artfct_sd_tresh,  # number of std-dev from mean that is used as cut-off\n",
    "        # to save: give directory, to show inline: give 'show', w/o fig: None\n",
    "        save=None,  # if None: no figure saved\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bandpass Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(fltrs)\n",
    "\n",
    "data_bp = {}\n",
    "for group in groups:\n",
    "    data_bp[group] = fltrs.bp_filter(\n",
    "        clean_dict=data_clean,\n",
    "        group=group,\n",
    "        sfreq=getattr(settings, group).Fs_orig,\n",
    "        l_freq=getattr(settings, group).bandpass_f[0],\n",
    "        h_freq=getattr(settings, group).bandpass_f[1],\n",
    "        method='iir',  # faster than fir\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Notch-filtering for Powerline Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Notch-Filter GROUP: lfp_left\n",
      "Start Notch-Filter GROUP: lfp_right\n",
      "Start Notch-Filter GROUP: ecog\n"
     ]
    }
   ],
   "source": [
    "# notch filtering in BLOCKS\n",
    "\n",
    "importlib.reload(fltrs)\n",
    "save_dir = os.path.join(\n",
    "    figpath,\n",
    "    'preprocessing',\n",
    "    runInfo0.store_str,\n",
    "    getattr(settings, group).settings_f_name,\n",
    ")\n",
    "data_nf = {}\n",
    "for group in data_bp.keys():\n",
    "    print(f'Start Notch-Filter GROUP: {group}')\n",
    "    data_nf[group] = fltrs.notch_filter(\n",
    "        bp_dict=data_bp,  # NOT DICT ANYMORE MORE BUT NAMEDTUPLE!!!\n",
    "        group=group,  # CALLS getattr() INSIDE FUNCTION WITH GROUP; CHANGE TO getattr() HERE??\n",
    "        transBW=getattr(settings, group).transBW,  # based on figures for now: 10\n",
    "        notchW=getattr(settings, group).notchW,  # based on figures for now: 2\n",
    "        method='fir',  #iir (8th or. Butterwidth) takes too long\n",
    "        ch_names=ch_nms_clean,\n",
    "        save=None,  # if None: no figures made and saved\n",
    "        verbose=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Resampling\n",
    "\n",
    "\n",
    "Since freq's of interest are up to +/- 100 - 120 Hz, according to the Nyquist-theorem the max sample freq does not need to be more than double (~ 250 Hz).\n",
    "\n",
    "Check differences with resampling to 400 or 800 Hz later. Or working with wider windows.\n",
    "- Swann '16: 800 Hz\n",
    "- Heger/ Herff: 600 Hz (https://www.csl.uni-bremen.de/cms/images/documents/publications/IS2015_brain2text.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(preproc)\n",
    "\n",
    "# resampling one run at a time\n",
    "data_rs = {}  # dict to store resampled data\n",
    "for group in groups:\n",
    "    data_rs[group] = preproc.resample(\n",
    "        data=data_nf,\n",
    "        group=group,\n",
    "        Fs_orig=getattr(settings, 'ecog').Fs_orig,\n",
    "        Fs_new = getattr(settings, 'ecog').Fs_resample,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Rereferencing\n",
    "\n",
    "\n",
    "\n",
    "Common Practice LFP Re-referencing: difference between two nieghbouring contacts\n",
    "- For segmented Leads: average every level\n",
    "\n",
    "\n",
    "Relevant ECOG-rereferencing literature used: \n",
    "- Common Average Rereferencing (Liu ea, J Neural Eng 2015 (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5485665/)\n",
    "- ECOG is local sign with spread +/- 3mm (Dubey, J Neurosc 2019): https://www.jneurosci.org/content/39/22/4299 \n",
    "- READ ON - DATA ANALYSIS: Relevance of data-driven spatial filtering for invasive EEG. For gamma: CAR is probably sufficient. For alpha-beta: ... Hihg inter-subject variability in ECOG. (Shaworonko & Voytek, PLOS Comp Biol 2021: https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009298)\n",
    "- Submilimeter (micro)ECOG: http://iebl.ucsd.edu/sites/iebl.ucsd.edu/files/2018-06/Sub-millimeter%20ECoG%20pitch%20in%20human%20enables%20higher%20%EF%AC%81delity%20cognitiveneural%20state%20estimation.pdf\n",
    "\n",
    "\n",
    "Check rereferencing methods:\n",
    "- de Cheveigne/Arzounian NeuroImage 2018\n",
    "- pre-prints Merk 2021 and Petersen 2021 (AG KÃ¼hn / AG Neumann)\n",
    "- pre-print epilepsy ecog movement (MUMC)\n",
    "\n",
    "\n",
    "P.M. Check further in to Spatial Filtering:\n",
    "- Spatial filter estimation via spatio-spectral decomposition: ............ TO READ   (Nikulin & Curio, NeuroImage 2011, https://www.sciencedirect.com/science/article/pii/S1053811911000930?via%3Dihub)\n",
    "- Spatio-Spectral Decomposition: proposed dimensionality-reduction instead of PCA (Haufe, ..., Nikulin, https://www.sciencedirect.com/science/article/pii/S1053811914005503?via%3Dihub)\n",
    "- Also check: SPoC (Castano et al NeuroImage Clin 2020)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= REREFERENCING OVERVIEW ======\n",
      "\n",
      "For lfp_left: Neigbouring Reref\n",
      "Sec check: No time row present in orig names\n",
      "Assume BS Vercise Cartesia X\n",
      "Level ('L', 0) contains rows 0:3, or: ['LFP_L_1_', 'LFP_L_2_', 'LFP_L_3_']\n",
      "Level ('L', 1) contains rows 3:6, or: ['LFP_L_4_', 'LFP_L_5_', 'LFP_L_6_']\n",
      "Level ('L', 2) contains rows 6:9, or: ['LFP_L_7_', 'LFP_L_8_', 'LFP_L_9_']\n",
      "Level ('L', 3) contains rows 9:12, or: ['LFP_L_10_', 'LFP_L_11_', 'LFP_L_12_']\n",
      "Level ('L', 4) contains rows 12:15, or: ['LFP_L_13_', 'LFP_L_14_', 'LFP_L_15_']\n",
      "Level ('L', 5) contains rows 15:15, or: []\n",
      "\n",
      " Auto Cleaning:\n",
      " In lfp_left: row 5 (LFP_L_4_5) only contained NaNs and is deleted\n",
      "\n",
      "\n",
      "======= REREFERENCING OVERVIEW ======\n",
      "\n",
      "For lfp_right: Neigbouring Reref\n",
      "Sec check: No time row present in orig names\n",
      "Assume BS Vercise Cartesia X\n",
      "Level ('R', 0) contains rows 0:2, or: ['LFP_R_1_', 'LFP_R_3_']\n",
      "Level ('R', 1) contains rows 2:4, or: ['LFP_R_4_', 'LFP_R_5_']\n",
      "Level ('R', 2) contains rows 4:6, or: ['LFP_R_8_', 'LFP_R_9_']\n",
      "Level ('R', 3) contains rows 6:9, or: ['LFP_R_10_', 'LFP_R_11_', 'LFP_R_12_']\n",
      "Level ('R', 4) contains rows 9:12, or: ['LFP_R_13_', 'LFP_R_14_', 'LFP_R_15_']\n",
      "Level ('R', 5) contains rows 12:13, or: ['LFP_R_16_']\n",
      "\n",
      "\n",
      "======= REREFERENCING OVERVIEW ======\n",
      "\n",
      "For ecog: Common Average Reref\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeroenhabets/Research/CHARITE/projects/dyskinesia_neurophys/code/py_neuromodulation/dyskinesia/reref.py:98: RuntimeWarning: Mean of empty slice\n",
      "  newdata[:, l + 1, :] = np.nanmean(\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(reref)\n",
    "data_rrf = {}\n",
    "names = {}\n",
    "for group in groups:\n",
    "    data_rrf[group], names[group] = reref.rereferencing(\n",
    "        data=data_rs,\n",
    "        group=group,\n",
    "        ch_names_og=ch_names,\n",
    "        ch_names_clean=ch_nms_clean,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Saving Preprocessed Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(preproc)\n",
    "for g in groups:\n",
    "    preproc.save_arrays(data=data_rrf, group=g, runInfo=runInfo0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load npy-files again\n",
    "temp = np.load(os.path.join(\n",
    "    f_dir, f_name))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3215b98ba4c40f90b358cffaa32696e7bfbdbe38275c45cfefc4b84b3a964fcf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ecog_dysk': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
